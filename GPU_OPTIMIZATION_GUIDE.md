# GPUè®­ç»ƒä¼˜åŒ–å®Œæ•´æŒ‡å—

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. è¯Šæ–­GPUçŠ¶æ€
```bash
python diagnose_gpu_usage.py
```

### 2. ä½¿ç”¨ä¼˜åŒ–è„šæœ¬è®­ç»ƒ
```bash
# Windows
train_gpu_optimized.bat

# Linux/Mac
bash train_gpu_optimized.sh
```

## ğŸ“Š ä½ çš„é—®é¢˜åˆ†æ

æ ¹æ®ä½ æä¾›çš„ä¿¡æ¯ï¼š
- **CPUä½¿ç”¨ç‡**: 3.19% (20æ ¸) - å¤ªä½ï¼Œè¯´æ˜CPUæ²¡æœ‰å……åˆ†å‡†å¤‡æ•°æ®
- **å†…å­˜ä½¿ç”¨**: 34.76% (116GB) - æ­£å¸¸
- **GPUä½¿ç”¨ç‡**: 1.64% - **å¤ªä½ï¼GPUå‡ ä¹ç©ºé—²**
- **æ˜¾å­˜ä½¿ç”¨**: 0.4GB / 22.5GB - **æ˜¾å­˜åˆ©ç”¨ç‡ä¸åˆ°2%**

### é—®é¢˜æ ¹æº

ä½ å½“å‰çš„è®­ç»ƒå‘½ä»¤ï¼š
```bash
python scripts/train_universal_model.py \
  --model-type lstm \
  --epochs 30 \
  --batch-size 64 \
  --hidden-size 64 \
  --stock-embedding-dim 16
```

**å­˜åœ¨çš„é—®é¢˜ï¼š**

1. âŒ **æœªå¯ç”¨æ··åˆç²¾åº¦è®­ç»ƒ** (`--amp`)
2. âŒ **batch_sizeå¤ªå°** (64) - GPUæ²¡æœ‰è¶³å¤Ÿçš„å¹¶è¡Œä»»åŠ¡
3. âŒ **hidden_sizeå¤ªå°** (64) - æ¨¡å‹å¤ªç®€å•ï¼ŒGPUç®—åŠ›æµªè´¹
4. âŒ **num_workersé»˜è®¤å€¼** (4) - æ•°æ®åŠ è½½é€Ÿåº¦è·Ÿä¸ä¸ŠGPU
5. âŒ **stock_embedding_dimå¤ªå°** (16) - æ¨¡å‹å‚æ•°é‡ä¸è¶³

## âœ… ä¼˜åŒ–æ–¹æ¡ˆ

### æ–¹æ¡ˆ1: æ¿€è¿›ä¼˜åŒ–ï¼ˆæ¨èï¼‰

å……åˆ†åˆ©ç”¨ä½ çš„22.5GBæ˜¾å­˜ï¼š

```bash
python scripts/train_universal_model.py \
  --model-type lstm \
  --epochs 30 \
  --batch-size 256 \
  --hidden-size 256 \
  --num-layers 3 \
  --stock-embedding-dim 64 \
  --learning-rate 0.001 \
  --device cuda \
  --amp \
  --num-workers 8 \
  --pin-memory \
  --output-dir out/universal_model_optimized
```

**é¢„æœŸæ•ˆæœï¼š**
- GPUä½¿ç”¨ç‡: 60-90%
- æ˜¾å­˜ä½¿ç”¨: 8-12GB
- è®­ç»ƒé€Ÿåº¦: æå‡5-10å€

### æ–¹æ¡ˆ2: ä¿å®ˆä¼˜åŒ–

å¦‚æœæ–¹æ¡ˆ1æ˜¾å­˜ä¸è¶³ï¼Œä½¿ç”¨è¿™ä¸ªï¼š

```bash
python scripts/train_universal_model.py \
  --model-type lstm \
  --epochs 30 \
  --batch-size 128 \
  --hidden-size 128 \
  --num-layers 2 \
  --stock-embedding-dim 32 \
  --learning-rate 0.001 \
  --device cuda \
  --amp \
  --num-workers 6 \
  --pin-memory \
  --output-dir out/universal_model_balanced
```

**é¢„æœŸæ•ˆæœï¼š**
- GPUä½¿ç”¨ç‡: 40-70%
- æ˜¾å­˜ä½¿ç”¨: 4-6GB
- è®­ç»ƒé€Ÿåº¦: æå‡3-5å€

### æ–¹æ¡ˆ3: æé™ä¼˜åŒ–

å¦‚æœä½ æƒ³æ¦¨å¹²GPUæ€§èƒ½ï¼š

```bash
python scripts/train_universal_model.py \
  --model-type lstm \
  --epochs 30 \
  --batch-size 512 \
  --hidden-size 512 \
  --num-layers 4 \
  --stock-embedding-dim 128 \
  --learning-rate 0.001 \
  --device cuda \
  --amp \
  --num-workers 12 \
  --pin-memory \
  --gradient-accumulation-steps 2 \
  --output-dir out/universal_model_extreme
```

**é¢„æœŸæ•ˆæœï¼š**
- GPUä½¿ç”¨ç‡: 80-95%
- æ˜¾å­˜ä½¿ç”¨: 15-20GB
- è®­ç»ƒé€Ÿåº¦: æå‡10-15å€

## ğŸ”§ å…³é”®å‚æ•°è¯´æ˜

### 1. `--amp` (æ··åˆç²¾åº¦è®­ç»ƒ)
- **ä½œç”¨**: ä½¿ç”¨FP16ä»£æ›¿FP32ï¼Œé€Ÿåº¦æå‡2-3å€ï¼Œæ˜¾å­˜å‡å°‘50%
- **å¿…é¡»å¯ç”¨**: æ˜¯
- **é€‚ç”¨åœºæ™¯**: æ‰€æœ‰GPUè®­ç»ƒ

### 2. `--batch-size`
- **ä½œç”¨**: æ¯æ‰¹å¤„ç†çš„æ ·æœ¬æ•°ï¼Œè¶Šå¤§GPUåˆ©ç”¨ç‡è¶Šé«˜
- **æ¨èå€¼**: 
  - å°æ˜¾å­˜(<8GB): 64-128
  - ä¸­æ˜¾å­˜(8-16GB): 128-256
  - å¤§æ˜¾å­˜(>16GB): 256-512
- **ä½ çš„æƒ…å†µ**: 256-512

### 3. `--hidden-size`
- **ä½œç”¨**: LSTMéšè—å±‚å¤§å°ï¼Œå½±å“æ¨¡å‹å¤æ‚åº¦
- **æ¨èå€¼**:
  - å¿«é€Ÿæµ‹è¯•: 64-128
  - æ­£å¸¸è®­ç»ƒ: 128-256
  - é«˜ç²¾åº¦: 256-512
- **ä½ çš„æƒ…å†µ**: 256-512

### 4. `--num-workers`
- **ä½œç”¨**: æ•°æ®åŠ è½½çš„å¹¶è¡Œè¿›ç¨‹æ•°
- **æ¨èå€¼**: CPUæ ¸å¿ƒæ•°çš„1/2åˆ°1/3
- **ä½ çš„æƒ…å†µ**: 6-10 (ä½ æœ‰20æ ¸CPU)

### 5. `--stock-embedding-dim`
- **ä½œç”¨**: è‚¡ç¥¨åµŒå…¥å‘é‡ç»´åº¦
- **æ¨èå€¼**: 32-128
- **ä½ çš„æƒ…å†µ**: 64-128

### 6. `--pin-memory`
- **ä½œç”¨**: ä½¿ç”¨é”é¡µå†…å­˜ï¼ŒåŠ é€ŸCPUåˆ°GPUæ•°æ®ä¼ è¾“
- **å¿…é¡»å¯ç”¨**: æ˜¯
- **æ€§èƒ½æå‡**: 10-30%

## ğŸ“ˆ æ€§èƒ½å¯¹æ¯”

### å½“å‰é…ç½® vs ä¼˜åŒ–é…ç½®

| æŒ‡æ ‡ | å½“å‰é…ç½® | ä¼˜åŒ–é…ç½® | æå‡ |
|------|---------|---------|------|
| batch_size | 64 | 256 | 4x |
| hidden_size | 64 | 256 | 4x |
| æ··åˆç²¾åº¦ | âŒ | âœ… | 2-3x |
| num_workers | 4 | 8 | 2x |
| GPUä½¿ç”¨ç‡ | 1.64% | 60-90% | 50x |
| æ˜¾å­˜ä½¿ç”¨ | 0.4GB | 8-12GB | 25x |
| **è®­ç»ƒé€Ÿåº¦** | **åŸºå‡†** | **5-10x** | **ğŸš€** |

## ğŸ¯ å®æˆ˜æ­¥éª¤

### æ­¥éª¤1: è¯Šæ–­å½“å‰çŠ¶æ€
```bash
python diagnose_gpu_usage.py
```

### æ­¥éª¤2: åœæ­¢å½“å‰è®­ç»ƒ
æŒ‰ `Ctrl+C` åœæ­¢å½“å‰è®­ç»ƒ

### æ­¥éª¤3: ä½¿ç”¨ä¼˜åŒ–å‘½ä»¤é‡æ–°è®­ç»ƒ

**Windows:**
```bash
train_gpu_optimized.bat
```

**Linux/Mac:**
```bash
bash train_gpu_optimized.sh
```

**æˆ–è€…ç›´æ¥è¿è¡Œ:**
```bash
python scripts/train_universal_model.py \
  --model-type lstm \
  --epochs 30 \
  --batch-size 256 \
  --hidden-size 256 \
  --num-layers 3 \
  --stock-embedding-dim 64 \
  --device cuda \
  --amp \
  --num-workers 8 \
  --pin-memory
```

### æ­¥éª¤4: ç›‘æ§GPUä½¿ç”¨

**å®æ—¶ç›‘æ§:**
```bash
# Linux
watch -n 1 nvidia-smi

# Windows (PowerShell)
while($true) { nvidia-smi; sleep 1; cls }
```

**é¢„æœŸçœ‹åˆ°:**
- GPUä½¿ç”¨ç‡: 60-90%
- æ˜¾å­˜ä½¿ç”¨: 8-12GB
- æ¸©åº¦: 60-80Â°C
- åŠŸè€—: æ¥è¿‘TDP

## ğŸ› å¸¸è§é—®é¢˜

### Q1: æ˜¾å­˜ä¸è¶³ (Out of Memory)
**è§£å†³æ–¹æ¡ˆ:**
1. å‡å° `--batch-size` (256 â†’ 128 â†’ 64)
2. å‡å° `--hidden-size` (256 â†’ 128)
3. å‡å°‘ `--num-layers` (3 â†’ 2)
4. å¯ç”¨æ¢¯åº¦ç´¯ç§¯: `--gradient-accumulation-steps 2`

### Q2: GPUä½¿ç”¨ç‡ä»ç„¶å¾ˆä½
**å¯èƒ½åŸå› :**
1. æ•°æ®åŠ è½½å¤ªæ…¢ â†’ å¢åŠ  `--num-workers`
2. batch_sizeå¤ªå° â†’ å¢å¤§ `--batch-size`
3. æ¨¡å‹å¤ªç®€å• â†’ å¢å¤§ `--hidden-size`
4. æœªå¯ç”¨æ··åˆç²¾åº¦ â†’ æ·»åŠ  `--amp`

### Q3: è®­ç»ƒé€Ÿåº¦æ²¡æœ‰æå‡
**æ£€æŸ¥æ¸…å•:**
- [ ] ç¡®è®¤ä½¿ç”¨äº† `--amp`
- [ ] ç¡®è®¤ `--batch-size >= 128`
- [ ] ç¡®è®¤ `--num-workers >= 4`
- [ ] ç¡®è®¤ `--device cuda`
- [ ] ç¡®è®¤æ•°æ®å·²ç¼“å­˜åˆ° `data/features/`

### Q4: æ•°æ®åŠ è½½æ…¢
**è§£å†³æ–¹æ¡ˆ:**
1. ç¡®ä¿ä½¿ç”¨ç¼“å­˜æ•°æ®ï¼ˆé»˜è®¤å¯ç”¨ï¼‰
2. å¢åŠ  `--num-workers` (8-12)
3. å¯ç”¨ `--pin-memory`
4. ä½¿ç”¨SSDå­˜å‚¨ç¼“å­˜æ•°æ®

## ğŸ“Š ç›‘æ§æŒ‡æ ‡

### ç†æƒ³çŠ¶æ€
```
GPUä½¿ç”¨ç‡: 70-90%
æ˜¾å­˜ä½¿ç”¨: 50-80% (11-18GB / 22.5GB)
CPUä½¿ç”¨ç‡: 20-40% (æ•°æ®åŠ è½½)
è®­ç»ƒé€Ÿåº¦: æ¯è½® < 60ç§’
```

### å½“å‰çŠ¶æ€ï¼ˆéœ€è¦ä¼˜åŒ–ï¼‰
```
GPUä½¿ç”¨ç‡: 1.64% âŒ
æ˜¾å­˜ä½¿ç”¨: 1.8% (0.4GB / 22.5GB) âŒ
CPUä½¿ç”¨ç‡: 3.19% âŒ
è®­ç»ƒé€Ÿåº¦: æ¯è½® > 300ç§’ âŒ
```

## ğŸ“ è¿›é˜¶ä¼˜åŒ–

### 1. ä½¿ç”¨Transformeræ¨¡å‹
```bash
python scripts/train_universal_model.py \
  --model-type transformer \
  --batch-size 128 \
  --hidden-size 256 \
  --amp \
  --num-workers 8
```

### 2. å¤šGPUè®­ç»ƒ
```bash
# ä½¿ç”¨DataParallel
CUDA_VISIBLE_DEVICES=0,1 python scripts/train_universal_model.py \
  --batch-size 512 \
  --amp
```

### 3. æ¢¯åº¦ç´¯ç§¯ï¼ˆæ¨¡æ‹Ÿæ›´å¤§batchï¼‰
```bash
python scripts/train_universal_model.py \
  --batch-size 128 \
  --gradient-accumulation-steps 4 \
  --amp
# ç­‰æ•ˆäº batch_size=512
```

## ğŸ“ æ€»ç»“

### ç«‹å³æ‰§è¡Œçš„ä¼˜åŒ–
1. âœ… æ·»åŠ  `--amp` å‚æ•°
2. âœ… å¢å¤§ `--batch-size` åˆ° 256
3. âœ… å¢å¤§ `--hidden-size` åˆ° 256
4. âœ… å¢åŠ  `--num-workers` åˆ° 8
5. âœ… ç¡®ä¿ `--pin-memory` å¯ç”¨

### é¢„æœŸç»“æœ
- ğŸš€ è®­ç»ƒé€Ÿåº¦æå‡ **5-10å€**
- ğŸ’ª GPUä½¿ç”¨ç‡æå‡åˆ° **60-90%**
- ğŸ“ˆ æ˜¾å­˜ä½¿ç”¨æå‡åˆ° **8-12GB**
- âš¡ æ¯è½®è®­ç»ƒæ—¶é—´ä» **5åˆ†é’Ÿ** é™åˆ° **30-60ç§’**

### ä¸‹ä¸€æ­¥
```bash
# 1. è¿è¡Œè¯Šæ–­
python diagnose_gpu_usage.py

# 2. ä½¿ç”¨ä¼˜åŒ–è„šæœ¬
train_gpu_optimized.bat  # Windows
# æˆ–
bash train_gpu_optimized.sh  # Linux/Mac

# 3. ç›‘æ§GPU
nvidia-smi -l 1
```

---

**éœ€è¦å¸®åŠ©ï¼Ÿ** è¿è¡Œ `python diagnose_gpu_usage.py` è·å–è¯¦ç»†è¯Šæ–­æŠ¥å‘Šã€‚
