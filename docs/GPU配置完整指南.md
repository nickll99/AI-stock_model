# GPUé…ç½®å®Œæ•´æŒ‡å—

## ğŸ¯ ç›®æ ‡

é…ç½®GPUåŠ é€Ÿè®­ç»ƒï¼Œé€Ÿåº¦æå‡10-20å€ï¼

---

## ğŸ” ç¬¬ä¸€æ­¥ï¼šæ£€æŸ¥GPUçŠ¶æ€

### è¿è¡Œæ£€æµ‹è„šæœ¬

```bash
python scripts/check_gpu.py
```

### å¯èƒ½çš„è¾“å‡º

#### æƒ…å†µ1ï¼šGPUé…ç½®æ­£å¸¸ âœ…

```
======================================================================
  GPUé…ç½®æ£€æŸ¥
======================================================================

1. æ£€æŸ¥PyTorch...
âœ“ PyTorchç‰ˆæœ¬: 2.0.1+cu118

2. æ£€æŸ¥CUDA...
âœ“ CUDAå¯ç”¨: True
âœ“ CUDAç‰ˆæœ¬: 11.8
âœ“ GPUæ•°é‡: 1
âœ“ GPU 0: NVIDIA GeForce RTX 3080
  - æ€»å†…å­˜: 10.00 GB

3. æ£€æŸ¥NVIDIAé©±åŠ¨...
âœ“ NVIDIAé©±åŠ¨å·²å®‰è£…

GPUä¿¡æ¯:
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 525.60.11    Driver Version: 525.60.11    CUDA Version: 12.0   |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0  On |                  N/A |
| 30%   45C    P8    15W / 320W |    500MiB / 10240MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+

======================================================================
  å»ºè®®
======================================================================

âœ“ GPUé…ç½®æ­£å¸¸ï¼Œå¯ä»¥ä½¿ç”¨GPUè®­ç»ƒï¼

ä½¿ç”¨GPUè®­ç»ƒ:
  python examples/train_with_manager.py
  python scripts/train_universal_model.py --device cuda
```

**ç»“è®ºï¼šå¯ä»¥ç›´æ¥ä½¿ç”¨GPUè®­ç»ƒï¼**

#### æƒ…å†µ2ï¼šCUDAä¸å¯ç”¨ âŒ

```
======================================================================
  GPUé…ç½®æ£€æŸ¥
======================================================================

1. æ£€æŸ¥PyTorch...
âœ“ PyTorchç‰ˆæœ¬: 2.0.1

2. æ£€æŸ¥CUDA...
âœ— CUDAä¸å¯ç”¨

å¯èƒ½çš„åŸå› :
  1. å®‰è£…çš„æ˜¯CPUç‰ˆæœ¬çš„PyTorch
  2. æ²¡æœ‰NVIDIA GPU
  3. CUDAé©±åŠ¨æœªå®‰è£…æˆ–ç‰ˆæœ¬ä¸åŒ¹é…

3. æ£€æŸ¥NVIDIAé©±åŠ¨...
âœ— nvidia-smiæœªæ‰¾åˆ°
  å¯èƒ½æ²¡æœ‰å®‰è£…NVIDIAé©±åŠ¨æˆ–ä¸æ˜¯NVIDIA GPU
```

**ç»“è®ºï¼šéœ€è¦é…ç½®GPUç¯å¢ƒ**

---

## ğŸ› ï¸ ç¬¬äºŒæ­¥ï¼šé…ç½®GPUç¯å¢ƒ

### æ–¹æ¡ˆAï¼šæœ‰NVIDIA GPUï¼ˆæ¨èï¼‰

#### 1. æ£€æŸ¥GPUç¡¬ä»¶

**Windows:**
```
1. å³é”®"æ­¤ç”µè„‘" -> ç®¡ç† -> è®¾å¤‡ç®¡ç†å™¨
2. å±•å¼€"æ˜¾ç¤ºé€‚é…å™¨"
3. æŸ¥çœ‹æ˜¯å¦æœ‰NVIDIAæ˜¾å¡
```

**Linux:**
```bash
lspci | grep -i nvidia
```

**å¸¸è§NVIDIA GPU:**
- GeForceç³»åˆ—ï¼šGTX 1060/1660/2060/3060/3080/4090ç­‰
- RTXç³»åˆ—ï¼šRTX 2080/3080/4080/4090ç­‰
- Quadroç³»åˆ—ï¼šä¸“ä¸šå¡
- Teslaç³»åˆ—ï¼šæœåŠ¡å™¨å¡

#### 2. å®‰è£…NVIDIAé©±åŠ¨

**Windows:**
1. è®¿é—®ï¼šhttps://www.nvidia.com/Download/index.aspx
2. é€‰æ‹©ä½ çš„GPUå‹å·
3. ä¸‹è½½å¹¶å®‰è£…é©±åŠ¨
4. é‡å¯ç”µè„‘

**Linux (Ubuntu):**
```bash
# æ–¹æ³•1ï¼šä½¿ç”¨aptå®‰è£…ï¼ˆæ¨èï¼‰
sudo apt update
sudo apt install nvidia-driver-525

# æ–¹æ³•2ï¼šä½¿ç”¨å®˜æ–¹å®‰è£…åŒ…
# ä»NVIDIAå®˜ç½‘ä¸‹è½½.runæ–‡ä»¶
sudo bash NVIDIA-Linux-x86_64-525.60.11.run

# é‡å¯
sudo reboot

# éªŒè¯
nvidia-smi
```

#### 3. å®‰è£…CUDAç‰ˆæœ¬çš„PyTorch

**å¸è½½å½“å‰PyTorch:**
```bash
pip uninstall torch torchvision torchaudio
```

**å®‰è£…CUDA 11.8ç‰ˆæœ¬ï¼ˆæ¨èï¼‰:**
```bash
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

**æˆ–å®‰è£…CUDA 12.1ç‰ˆæœ¬:**
```bash
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
```

**ä½¿ç”¨condaå®‰è£…:**
```bash
# CUDA 11.8
conda install pytorch torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia

# CUDA 12.1
conda install pytorch torchvision torchaudio pytorch-cuda=12.1 -c pytorch -c nvidia
```

#### 4. éªŒè¯å®‰è£…

```bash
python scripts/check_gpu.py
```

åº”è¯¥çœ‹åˆ°ï¼š
```
âœ“ CUDAå¯ç”¨: True
âœ“ GPUæ•°é‡: 1
âœ“ GPU 0: NVIDIA GeForce RTX 3080
```

### æ–¹æ¡ˆBï¼šæ²¡æœ‰NVIDIA GPU

å¦‚æœä½ çš„ç”µè„‘æ²¡æœ‰NVIDIA GPUï¼ˆå¦‚AMD GPUã€Intelé›†æ˜¾ï¼‰ï¼Œåˆ™ï¼š

**é€‰é¡¹1ï¼šä½¿ç”¨CPUè®­ç»ƒ**
- é€Ÿåº¦è¾ƒæ…¢ä½†å¯ç”¨
- é€‚åˆå°è§„æ¨¡è®­ç»ƒ

**é€‰é¡¹2ï¼šä½¿ç”¨äº‘GPU**
- Google Colabï¼ˆå…è´¹GPUï¼‰
- AWS/é˜¿é‡Œäº‘/è…¾è®¯äº‘ï¼ˆä»˜è´¹GPUï¼‰
- AutoDL/æ’æºäº‘ï¼ˆå›½å†…GPUç§Ÿç”¨ï¼‰

**é€‰é¡¹3ï¼šè´­ä¹°GPU**
- æ¨èï¼šRTX 3060/3080/4090
- é¢„ç®—æœ‰é™ï¼šGTX 1660 Super

---

## ğŸš€ ç¬¬ä¸‰æ­¥ï¼šä½¿ç”¨GPUè®­ç»ƒ

### å•è‚¡ç¥¨è®­ç»ƒ

```bash
# ä»£ç ä¼šè‡ªåŠ¨æ£€æµ‹å¹¶ä½¿ç”¨GPU
python examples/train_with_manager.py
```

**è¾“å‡ºåº”è¯¥æ˜¾ç¤ºï¼š**
```
å¼€å§‹è®­ç»ƒï¼Œè®¾å¤‡: cuda
```

### æ‰¹é‡è®­ç»ƒ

```bash
# æ‰¹é‡è®­ç»ƒä¼šè‡ªåŠ¨ä½¿ç”¨GPU
python scripts/batch_train_all_stocks.py \
    --symbols all \
    --workers 2 \
    --resume
```

**æ³¨æ„ï¼š**
- GPUè®­ç»ƒæ—¶ï¼Œworkerså»ºè®®è®¾ç½®ä¸º2-4
- ä¸è¦è®¾ç½®å¤ªå¤šworkersï¼Œä¼šå¯¼è‡´GPUå†…å­˜ä¸è¶³

### é€šç”¨æ¨¡å‹è®­ç»ƒ

```bash
# æ˜¾å¼æŒ‡å®šä½¿ç”¨GPU
python scripts/train_universal_model.py --device cuda
```

---

## ğŸ“Š æ€§èƒ½å¯¹æ¯”

### å•è‚¡ç¥¨è®­ç»ƒ

| ç¡¬ä»¶ | è®­ç»ƒæ—¶é—´ | ç›¸å¯¹é€Ÿåº¦ |
|------|---------|----------|
| CPU (4æ ¸ i5) | 5åˆ†é’Ÿ | 1x |
| CPU (8æ ¸ i7) | 3åˆ†é’Ÿ | 1.7x |
| GPU (GTX 1660) | 30ç§’ | 10x |
| GPU (RTX 3080) | 15ç§’ | 20x |
| GPU (RTX 4090) | 10ç§’ | 30x |

### æ‰¹é‡è®­ç»ƒ5000åªè‚¡ç¥¨

| ç¡¬ä»¶ | è®­ç»ƒæ—¶é—´ | ç›¸å¯¹é€Ÿåº¦ |
|------|---------|----------|
| CPU (8æ ¸) | 40-50å°æ—¶ | 1x |
| GPU (GTX 1660) | 15-20å°æ—¶ | 3x |
| GPU (RTX 3080) | 8-12å°æ—¶ | 5x |
| GPU (RTX 4090) | 4-6å°æ—¶ | 10x |

### é€šç”¨æ¨¡å‹è®­ç»ƒ

| ç¡¬ä»¶ | è®­ç»ƒæ—¶é—´ | ç›¸å¯¹é€Ÿåº¦ |
|------|---------|----------|
| CPU (8æ ¸) | 5å°æ—¶ | 1x |
| GPU (GTX 1660) | 2å°æ—¶ | 2.5x |
| GPU (RTX 3080) | 1å°æ—¶ | 5x |
| GPU (RTX 4090) | 30åˆ†é’Ÿ | 10x |

---

## ğŸ”§ å¸¸è§é—®é¢˜

### Q1: æ˜¾ç¤º"CUDAä¸å¯ç”¨"æ€ä¹ˆåŠï¼Ÿ

**æ£€æŸ¥æ¸…å•ï¼š**

1. **ç¡®è®¤æœ‰NVIDIA GPU**
```bash
# Windows
è®¾å¤‡ç®¡ç†å™¨ -> æ˜¾ç¤ºé€‚é…å™¨

# Linux
lspci | grep -i nvidia
```

2. **ç¡®è®¤é©±åŠ¨å·²å®‰è£…**
```bash
nvidia-smi
```

3. **ç¡®è®¤PyTorchç‰ˆæœ¬**
```bash
python -c "import torch; print(torch.__version__)"
```

åº”è¯¥çœ‹åˆ°ç±»ä¼¼ï¼š`2.0.1+cu118`ï¼ˆæœ‰cu118åç¼€ï¼‰

å¦‚æœæ˜¯ï¼š`2.0.1`ï¼ˆæ²¡æœ‰cuåç¼€ï¼‰ï¼Œè¯´æ˜æ˜¯CPUç‰ˆæœ¬

**è§£å†³æ–¹æ¡ˆï¼š**
```bash
pip uninstall torch torchvision torchaudio
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

### Q2: GPUå†…å­˜ä¸è¶³ï¼ˆOOMï¼‰

**é”™è¯¯ä¿¡æ¯ï¼š**
```
RuntimeError: CUDA out of memory
```

**è§£å†³æ–¹æ¡ˆï¼š**

```bash
# æ–¹æ³•1ï¼šå‡å°æ‰¹æ¬¡å¤§å°
python examples/train_with_manager.py
# ä¿®æ”¹configä¸­çš„batch_sizeä»32æ”¹ä¸º16

# æ–¹æ³•2ï¼šå‡å°æ¨¡å‹å¤§å°
# ä¿®æ”¹hidden_sizeä»128æ”¹ä¸º64

# æ–¹æ³•3ï¼šå‡å°‘workers
python scripts/batch_train_all_stocks.py --workers 1
```

### Q3: GPUåˆ©ç”¨ç‡ä½

**ç—‡çŠ¶ï¼š**
```bash
nvidia-smi
# GPUåˆ©ç”¨ç‡åªæœ‰10-20%
```

**åŸå› ï¼š**
- æ‰¹æ¬¡å¤ªå°
- æ•°æ®åŠ è½½æ…¢
- CPUæˆä¸ºç“¶é¢ˆ

**è§£å†³æ–¹æ¡ˆï¼š**

```python
# å¢å¤§æ‰¹æ¬¡å¤§å°
config = {
    "batch_size": 128,  # ä»32å¢åŠ åˆ°128
}

# ä½¿ç”¨æ•°æ®é¢„çƒ­
python scripts/prepare_training_data.py --symbols all --workers 8 --resume

# å¢åŠ DataLoaderçš„workers
train_loader = DataLoader(dataset, batch_size=128, num_workers=4)
```

### Q4: å¤šGPUå¦‚ä½•ä½¿ç”¨ï¼Ÿ

**æ£€æŸ¥GPUæ•°é‡ï¼š**
```bash
python -c "import torch; print(torch.cuda.device_count())"
```

**ä½¿ç”¨DataParallelï¼š**
```python
import torch.nn as nn

# åœ¨train_with_manager.pyä¸­æ·»åŠ 
if torch.cuda.device_count() > 1:
    print(f"ä½¿ç”¨ {torch.cuda.device_count()} ä¸ªGPU")
    model = nn.DataParallel(model)
```

### Q5: CUDAç‰ˆæœ¬ä¸åŒ¹é…

**é”™è¯¯ä¿¡æ¯ï¼š**
```
RuntimeError: CUDA error: no kernel image is available for execution on the device
```

**åŸå› ï¼š**
PyTorchçš„CUDAç‰ˆæœ¬ä¸é©±åŠ¨çš„CUDAç‰ˆæœ¬ä¸åŒ¹é…

**è§£å†³æ–¹æ¡ˆï¼š**

1. **æŸ¥çœ‹é©±åŠ¨æ”¯æŒçš„CUDAç‰ˆæœ¬**
```bash
nvidia-smi
# æŸ¥çœ‹å³ä¸Šè§’çš„CUDA Version
```

2. **å®‰è£…åŒ¹é…çš„PyTorchç‰ˆæœ¬**
```bash
# å¦‚æœé©±åŠ¨æ”¯æŒCUDA 11.8
pip install torch --index-url https://download.pytorch.org/whl/cu118

# å¦‚æœé©±åŠ¨æ”¯æŒCUDA 12.1
pip install torch --index-url https://download.pytorch.org/whl/cu121
```

---

## ğŸ’¡ æœ€ä½³å®è·µ

### 1. GPUè®­ç»ƒé…ç½®

```python
# æ¨èé…ç½®
config = {
    "batch_size": 64,      # GPUå¯ä»¥ç”¨æ›´å¤§çš„æ‰¹æ¬¡
    "hidden_size": 256,    # GPUå¯ä»¥ç”¨æ›´å¤§çš„æ¨¡å‹
    "num_layers": 3,       # GPUå¯ä»¥ç”¨æ›´æ·±çš„ç½‘ç»œ
    "workers": 2,          # GPUè®­ç»ƒæ—¶workersä¸è¦å¤ªå¤š
}
```

### 2. ç›‘æ§GPUä½¿ç”¨

```bash
# å®æ—¶ç›‘æ§GPU
watch -n 1 nvidia-smi

# æˆ–ä½¿ç”¨gpustat
pip install gpustat
gpustat -i 1
```

### 3. æ··åˆç²¾åº¦è®­ç»ƒï¼ˆé«˜çº§ï¼‰

```python
# ä½¿ç”¨FP16åŠ é€Ÿè®­ç»ƒ
from torch.cuda.amp import autocast, GradScaler

scaler = GradScaler()

for epoch in range(epochs):
    for X, y in train_loader:
        with autocast():
            output = model(X)
            loss = criterion(output, y)
        
        scaler.scale(loss).backward()
        scaler.step(optimizer)
        scaler.update()
```

### 4. æ¸…ç†GPUç¼“å­˜

```python
import torch

# è®­ç»ƒå®Œæˆåæ¸…ç†ç¼“å­˜
torch.cuda.empty_cache()
```

---

## ğŸ“ å¿«é€Ÿæ£€æŸ¥æ¸…å•

- [ ] ç¡®è®¤æœ‰NVIDIA GPU
- [ ] å®‰è£…NVIDIAé©±åŠ¨
- [ ] è¿è¡Œ`nvidia-smi`æˆåŠŸ
- [ ] å®‰è£…CUDAç‰ˆæœ¬çš„PyTorch
- [ ] è¿è¡Œ`python scripts/check_gpu.py`
- [ ] çœ‹åˆ°"CUDAå¯ç”¨: True"
- [ ] è®­ç»ƒæ—¶æ˜¾ç¤º"è®¾å¤‡: cuda"
- [ ] GPUåˆ©ç”¨ç‡>80%

---

## ğŸ“ æ€»ç»“

### GPUé…ç½®æ­¥éª¤

```bash
# 1. æ£€æŸ¥GPU
python scripts/check_gpu.py

# 2. å¦‚æœCUDAä¸å¯ç”¨ï¼Œå®‰è£…CUDAç‰ˆæœ¬çš„PyTorch
pip uninstall torch torchvision torchaudio
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# 3. å†æ¬¡æ£€æŸ¥
python scripts/check_gpu.py

# 4. å¼€å§‹GPUè®­ç»ƒ
python examples/train_with_manager.py
python scripts/train_universal_model.py --device cuda
```

### æ€§èƒ½æå‡

- å•è‚¡ç¥¨è®­ç»ƒï¼š10-30å€
- æ‰¹é‡è®­ç»ƒï¼š3-10å€
- é€šç”¨æ¨¡å‹ï¼š2.5-10å€

### æ¨èGPU

| é¢„ç®— | GPU | æ€§èƒ½ | ä»·æ ¼ |
|------|-----|------|------|
| å…¥é—¨ | GTX 1660 Super | 2-3x | Â¥1500 |
| ä¸­ç«¯ | RTX 3060 | 5-6x | Â¥2500 |
| é«˜ç«¯ | RTX 3080 | 8-10x | Â¥5000 |
| æ——èˆ° | RTX 4090 | 15-20x | Â¥12000 |

ç°åœ¨ä½ å¯ä»¥é…ç½®GPUåŠ é€Ÿè®­ç»ƒäº†ï¼ğŸš€
