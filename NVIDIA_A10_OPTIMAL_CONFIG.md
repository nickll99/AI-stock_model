# NVIDIA A10 æœ€ä¼˜è®­ç»ƒé…ç½®

## ğŸ¯ ä½ çš„GPUé…ç½®

```
GPU: NVIDIA A10
æ˜¾å­˜: 22.06 GB
CUDA: 12.8
é©±åŠ¨: 580.65.06
```

**è¿™æ˜¯ä¸€ä¸ªéå¸¸å¼ºå¤§çš„GPUï¼** å¯ä»¥å……åˆ†åˆ©ç”¨å¤§batch sizeå’Œæ··åˆç²¾åº¦è®­ç»ƒã€‚

---

## âš¡ æ¨èé…ç½®ï¼ˆæè‡´æ€§èƒ½ï¼‰

### é…ç½®1ï¼šæè‡´æ€§èƒ½ï¼ˆæ¨èï¼‰

```bash
python scripts/train_universal_model.py \
    --model-type transformer \
    --epochs 100 \
    --batch-size 1024 \
    --hidden-size 256 \
    --device cuda \
    --amp \
    --num-workers 4 \
    --pin-memory
```

**é¢„æœŸæ•ˆæœï¼š**
- è®­ç»ƒæ—¶é—´ï¼š1-1.5å°æ—¶ï¼ˆå…¨é‡3000åªè‚¡ç¥¨ï¼‰
- GPUåˆ©ç”¨ç‡ï¼š90-100%
- æ˜¾å­˜å ç”¨ï¼š16-20GB
- é€Ÿåº¦æå‡ï¼š4-5å€

### é…ç½®2ï¼šå¹³è¡¡é…ç½®

```bash
python scripts/train_universal_model.py \
    --model-type transformer \
    --epochs 100 \
    --batch-size 512 \
    --hidden-size 256 \
    --device cuda \
    --amp \
    --num-workers 4 \
    --pin-memory
```

**é¢„æœŸæ•ˆæœï¼š**
- è®­ç»ƒæ—¶é—´ï¼š1.5-2å°æ—¶
- GPUåˆ©ç”¨ç‡ï¼š85-95%
- æ˜¾å­˜å ç”¨ï¼š12-16GB
- é€Ÿåº¦æå‡ï¼š3-4å€

### é…ç½®3ï¼šå†…å­˜ä¼˜åŒ–ï¼ˆè§£å†³å†…å­˜å ç”¨50%é—®é¢˜ï¼‰

```bash
python scripts/train_universal_model.py \
    --model-type transformer \
    --epochs 100 \
    --batch-size 512 \
    --hidden-size 256 \
    --device cuda \
    --amp \
    --num-workers 2 \
    --pin-memory \
    --limit 1000
```

**é¢„æœŸæ•ˆæœï¼š**
- è®­ç»ƒæ—¶é—´ï¼š30-45åˆ†é’Ÿï¼ˆ1000åªè‚¡ç¥¨ï¼‰
- å†…å­˜å ç”¨ï¼š20-30%ï¼ˆé€šè¿‡é™åˆ¶è‚¡ç¥¨æ•°é‡ï¼‰
- GPUåˆ©ç”¨ç‡ï¼š90-100%
- æ˜¾å­˜å ç”¨ï¼š12-16GB

---

## ğŸ’¡ è§£å†³å†…å­˜å ç”¨50%é—®é¢˜

### é—®é¢˜åˆ†æ

**å½“å‰çŠ¶æ€ï¼š**
- âŒ å†…å­˜å ç”¨50%ï¼ˆæ•°æ®åŠ è½½é˜¶æ®µï¼‰
- âŒ GPUæ²¡æœ‰è¢«å……åˆ†åˆ©ç”¨

**åŸå› ï¼š**
æ•°æ®åŠ è½½é˜¶æ®µä¸€æ¬¡æ€§åŠ è½½æ‰€æœ‰è‚¡ç¥¨åˆ°å†…å­˜ï¼ˆ3000+åªè‚¡ç¥¨ï¼‰

### è§£å†³æ–¹æ¡ˆ

#### æ–¹æ¡ˆ1ï¼šé™åˆ¶è‚¡ç¥¨æ•°é‡ï¼ˆæ¨èï¼‰

```bash
# è®­ç»ƒ1000åªè‚¡ç¥¨ï¼ˆå†…å­˜å ç”¨é™åˆ°15-20%ï¼‰
python scripts/train_universal_model.py \
    --model-type transformer \
    --epochs 100 \
    --batch-size 1024 \
    --hidden-size 256 \
    --device cuda \
    --amp \
    --num-workers 4 \
    --pin-memory \
    --limit 1000
```

#### æ–¹æ¡ˆ2ï¼šåˆ†æ‰¹è®­ç»ƒ

```bash
# ç¬¬ä¸€æ‰¹ï¼šå‰1000åª
python scripts/train_universal_model.py \
    --device cuda \
    --amp \
    --batch-size 1024 \
    --limit 1000 \
    --output-dir out/universal_model_batch1

# ç¬¬äºŒæ‰¹ï¼š1000-2000åª
python scripts/train_universal_model.py \
    --device cuda \
    --amp \
    --batch-size 1024 \
    --limit 2000 \
    --output-dir out/universal_model_batch2
```

#### æ–¹æ¡ˆ3ï¼šå‡å°‘DataLoader workers

```bash
# ä½¿ç”¨2ä¸ªworkersè€Œä¸æ˜¯4ä¸ª
python scripts/train_universal_model.py \
    --device cuda \
    --amp \
    --batch-size 1024 \
    --num-workers 2 \
    --pin-memory
```

---

## ğŸš€ å®Œæ•´è®­ç»ƒæµç¨‹

### ç¬¬1æ­¥ï¼šå¿«é€Ÿæµ‹è¯•ï¼ˆ5åˆ†é’Ÿï¼‰

```bash
python scripts/train_universal_model.py \
    --device cuda \
    --amp \
    --limit 100 \
    --epochs 5 \
    --batch-size 512 \
    --num-workers 2
```

**æ£€æŸ¥é¡¹ï¼š**
- âœ… è®¾å¤‡æ˜¾ç¤ºä¸º `cuda`
- âœ… æ··åˆç²¾åº¦æ˜¾ç¤ºä¸º `å¯ç”¨`
- âœ… æ¯ä¸ªepochæ—¶é—´åœ¨10-20ç§’
- âœ… GPUåˆ©ç”¨ç‡>80%

### ç¬¬2æ­¥ï¼šä¸­ç­‰è§„æ¨¡æµ‹è¯•ï¼ˆ30åˆ†é’Ÿï¼‰

```bash
python scripts/train_universal_model.py \
    --model-type transformer \
    --epochs 20 \
    --batch-size 512 \
    --hidden-size 256 \
    --device cuda \
    --amp \
    --num-workers 4 \
    --pin-memory \
    --limit 500
```

### ç¬¬3æ­¥ï¼šå…¨é‡è®­ç»ƒï¼ˆ1-2å°æ—¶ï¼‰

```bash
python scripts/train_universal_model.py \
    --model-type transformer \
    --epochs 100 \
    --batch-size 1024 \
    --hidden-size 256 \
    --device cuda \
    --amp \
    --num-workers 4 \
    --pin-memory \
    --limit 1000
```

---

## ğŸ“Š æ€§èƒ½é¢„æœŸ

### NVIDIA A10 æ€§èƒ½å¯¹æ¯”

| é…ç½® | Batch Size | è®­ç»ƒæ—¶é—´ | GPUåˆ©ç”¨ç‡ | æ˜¾å­˜å ç”¨ |
|------|-----------|---------|----------|---------|
| åŸºç¡€ | 128 | 4å°æ—¶ | 40-50% | 6GB |
| ä¼˜åŒ– | 512 | 1.5å°æ—¶ | 85-95% | 14GB |
| æè‡´ | 1024 | 1å°æ—¶ | 95-100% | 18GB |

### vs å…¶ä»–GPU

| GPU | æ˜¾å­˜ | è®­ç»ƒæ—¶é—´ | è¯´æ˜ |
|-----|------|---------|------|
| GTX 1660 | 6GB | 2å°æ—¶ | å…¥é—¨çº§ |
| RTX 3080 | 10GB | 1å°æ—¶ | é«˜æ€§èƒ½ |
| **A10** | **22GB** | **1å°æ—¶** | **ä¸“ä¸šçº§** |
| RTX 4090 | 24GB | 30åˆ†é’Ÿ | æ——èˆ°çº§ |

---

## ğŸ” ç›‘æ§å’Œä¼˜åŒ–

### å®æ—¶ç›‘æ§GPU

```bash
# åœ¨å¦ä¸€ä¸ªç»ˆç«¯è¿è¡Œ
watch -n 1 nvidia-smi
```

**ç›®æ ‡çŠ¶æ€ï¼š**
```
+-----------------------------------------------------------------------------------------+
| GPU  Name                 | GPU-Util  | Memory-Usage |
|=========================================================================================|
|   0  NVIDIA A10           |    98%    |  18GB / 22GB |  â† ç›®æ ‡çŠ¶æ€
+-----------------------------------------------------------------------------------------+
```

### ç›‘æ§å†…å­˜

```bash
# ç›‘æ§ç³»ç»Ÿå†…å­˜
watch -n 1 free -h
```

**ç›®æ ‡çŠ¶æ€ï¼š**
- å†…å­˜å ç”¨ï¼š20-30%ï¼ˆé€šè¿‡é™åˆ¶è‚¡ç¥¨æ•°é‡ï¼‰
- å¯ç”¨å†…å­˜ï¼š>50%

### ä¼˜åŒ–å»ºè®®

**å¦‚æœGPUåˆ©ç”¨ç‡ä½ï¼ˆ<80%ï¼‰ï¼š**
1. å¢å¤§batch sizeï¼š`--batch-size 1024` æˆ– `2048`
2. å¢åŠ workersï¼š`--num-workers 8`
3. ç¡®ä¿ä½¿ç”¨ç¼“å­˜æ•°æ®

**å¦‚æœå†…å­˜å ç”¨é«˜ï¼ˆ>50%ï¼‰ï¼š**
1. é™åˆ¶è‚¡ç¥¨æ•°é‡ï¼š`--limit 1000`
2. å‡å°‘workersï¼š`--num-workers 2`
3. åˆ†æ‰¹è®­ç»ƒ

**å¦‚æœæ˜¾å­˜ä¸è¶³ï¼š**
1. å‡å°batch sizeï¼š`--batch-size 512`
2. å‡å°æ¨¡å‹ï¼š`--hidden-size 128`
3. ç¦ç”¨æ··åˆç²¾åº¦ï¼šç§»é™¤ `--amp`

---

## ğŸ¯ æ¨èå·¥ä½œæµ

### å¿«é€Ÿå¼€å§‹ï¼ˆæ¨èï¼‰

```bash
# 1. ç¡®ä¿æ•°æ®å·²é¢„çƒ­
python scripts/prepare_training_data.py --symbols all --workers 8 --resume

# 2. å¿«é€Ÿæµ‹è¯•ï¼ˆ5åˆ†é’Ÿï¼‰
python scripts/train_universal_model.py \
    --device cuda \
    --amp \
    --limit 100 \
    --epochs 5 \
    --batch-size 512

# 3. ç›‘æ§GPUï¼ˆå¦ä¸€ä¸ªç»ˆç«¯ï¼‰
watch -n 1 nvidia-smi

# 4. æ­£å¼è®­ç»ƒï¼ˆ1-2å°æ—¶ï¼‰
python scripts/train_universal_model.py \
    --model-type transformer \
    --epochs 100 \
    --batch-size 1024 \
    --hidden-size 256 \
    --device cuda \
    --amp \
    --num-workers 4 \
    --pin-memory \
    --limit 1000
```

---

## ğŸ“ å‚æ•°è¯¦è§£

### å…³é”®å‚æ•°

| å‚æ•° | æ¨èå€¼ | è¯´æ˜ |
|------|--------|------|
| `--batch-size` | 1024 | A10å¯ä»¥æ”¯æŒå¾ˆå¤§çš„batch size |
| `--hidden-size` | 256 | å¹³è¡¡æ€§èƒ½å’Œç²¾åº¦ |
| `--amp` | å¯ç”¨ | æ··åˆç²¾åº¦ï¼Œé€Ÿåº¦æå‡2-3å€ |
| `--num-workers` | 4 | å¤šè¿›ç¨‹åŠ è½½æ•°æ® |
| `--pin-memory` | å¯ç”¨ | åŠ é€Ÿæ•°æ®ä¼ è¾“ |
| `--limit` | 1000 | é™åˆ¶è‚¡ç¥¨æ•°é‡ï¼Œå‡å°‘å†…å­˜å ç”¨ |

### Batch Sizeé€‰æ‹©

| æ˜¾å­˜å ç”¨ç›®æ ‡ | Batch Size | è¯´æ˜ |
|------------|-----------|------|
| 50% (11GB) | 512 | ä¿å®ˆé…ç½® |
| 70% (15GB) | 1024 | æ¨èé…ç½® |
| 85% (19GB) | 2048 | æè‡´é…ç½® |

---

## ğŸ”§ å¸¸è§é—®é¢˜

### Q1: å†…å­˜å ç”¨50%æ€ä¹ˆåŠï¼Ÿ

**è§£å†³æ–¹æ¡ˆï¼š**
```bash
# é™åˆ¶è‚¡ç¥¨æ•°é‡åˆ°1000åª
python scripts/train_universal_model.py \
    --device cuda \
    --amp \
    --batch-size 1024 \
    --limit 1000
```

**æ•ˆæœï¼š** å†…å­˜å ç”¨é™åˆ°20-30%

### Q2: GPUåˆ©ç”¨ç‡ä½æ€ä¹ˆåŠï¼Ÿ

**è§£å†³æ–¹æ¡ˆï¼š**
```bash
# å¢å¤§batch size
python scripts/train_universal_model.py \
    --device cuda \
    --amp \
    --batch-size 2048 \
    --num-workers 8
```

### Q3: æ˜¾å­˜ä¸è¶³æ€ä¹ˆåŠï¼Ÿ

**è§£å†³æ–¹æ¡ˆï¼š**
```bash
# å‡å°batch size
python scripts/train_universal_model.py \
    --device cuda \
    --amp \
    --batch-size 512
```

### Q4: è®­ç»ƒé€Ÿåº¦æ²¡æœ‰æå‡ï¼Ÿ

**æ£€æŸ¥æ¸…å•ï¼š**
1. âœ… æ˜¯å¦ä½¿ç”¨äº† `--device cuda`ï¼Ÿ
2. âœ… æ˜¯å¦å¯ç”¨äº† `--amp`ï¼Ÿ
3. âœ… æ˜¯å¦ä½¿ç”¨äº†ç¼“å­˜æ•°æ®ï¼Ÿ
4. âœ… Batch sizeæ˜¯å¦è¶³å¤Ÿå¤§ï¼Ÿ

---

## âœ¨ æ€»ç»“

### ä½ çš„æœ€ä¼˜é…ç½®

```bash
# æè‡´æ€§èƒ½ + å†…å­˜ä¼˜åŒ–
python scripts/train_universal_model.py \
    --model-type transformer \
    --epochs 100 \
    --batch-size 1024 \
    --hidden-size 256 \
    --device cuda \
    --amp \
    --num-workers 4 \
    --pin-memory \
    --limit 1000
```

### é¢„æœŸæ•ˆæœ

- âœ… è®­ç»ƒæ—¶é—´ï¼š1-1.5å°æ—¶ï¼ˆ1000åªè‚¡ç¥¨ï¼‰
- âœ… GPUåˆ©ç”¨ç‡ï¼š90-100%
- âœ… æ˜¾å­˜å ç”¨ï¼š16-18GBï¼ˆ80%ï¼‰
- âœ… å†…å­˜å ç”¨ï¼š20-30%ï¼ˆé€šè¿‡é™åˆ¶è‚¡ç¥¨æ•°é‡ï¼‰
- âœ… é€Ÿåº¦æå‡ï¼š4-5å€

### å…³é”®è¦ç‚¹

1. âœ… **ä½¿ç”¨å¤§batch size** - A10æœ‰22GBæ˜¾å­˜ï¼Œå¯ä»¥ç”¨1024æˆ–æ›´å¤§
2. âœ… **å¯ç”¨æ··åˆç²¾åº¦** - `--amp` é€Ÿåº¦æå‡2-3å€
3. âœ… **é™åˆ¶è‚¡ç¥¨æ•°é‡** - `--limit 1000` è§£å†³å†…å­˜å ç”¨é—®é¢˜
4. âœ… **ä½¿ç”¨ç¼“å­˜æ•°æ®** - é¿å…ä»æ•°æ®åº“åŠ è½½
5. âœ… **å¤šworkers** - `--num-workers 4` åŠ é€Ÿæ•°æ®åŠ è½½

ç°åœ¨ä½ å¯ä»¥å……åˆ†åˆ©ç”¨NVIDIA A10è¿›è¡Œé«˜é€Ÿè®­ç»ƒäº†ï¼ğŸš€
