# GPU未被使用问题诊断

## 🎯 问题描述

**现象：**
- ✅ GPU检测正常（`torch.cuda.is_available() == True`）
- ✅ 内存占用50%（数据加载中）
- ❌ GPU利用率0%（GPU没有被使用）

**原因：** 训练脚本正在**数据加载阶段**，还没有开始训练！

---

## 🔍 问题分析

### 训练流程

```
1. 数据加载阶段（CPU密集）
   ├─ 从缓存加载3000+只股票数据
   ├─ 构建特征矩阵
   ├─ 创建训练/验证/测试集
   └─ 内存占用50%，GPU利用率0%  ← 你现在在这里
   
2. 模型创建阶段（GPU）
   ├─ 创建模型
   ├─ 移动模型到GPU
   └─ GPU显存开始占用
   
3. 训练阶段（GPU密集）
   ├─ 前向传播（GPU）
   ├─ 反向传播（GPU）
   ├─ 参数更新（GPU）
   └─ GPU利用率90-100%  ← 目标状态
```

### 为什么数据加载这么慢？

**原因：** 一次性加载3000+只股票的数据到内存

**时间估算：**
- 100只股票：10-20秒
- 500只股票：1-2分钟
- 1000只股票：2-4分钟
- 3000只股票：6-12分钟  ← 你可能在这里等待

---

## ✅ 解决方案

### 方案1：限制股票数量（推荐）

```bash
# 只训练1000只股票，数据加载只需2-4分钟
python scripts/train_universal_model.py \
    --model-type transformer \
    --epochs 100 \
    --batch-size 1024 \
    --hidden-size 256 \
    --device cuda \
    --amp \
    --num-workers 4 \
    --pin-memory \
    --limit 1000
```

**效果：**
- 数据加载时间：2-4分钟（vs 6-12分钟）
- 内存占用：20-30%（vs 50%）
- GPU很快开始工作

### 方案2：先用小规模测试

```bash
# 只用100只股票快速测试，数据加载只需10-20秒
python scripts/train_universal_model.py \
    --device cuda \
    --amp \
    --limit 100 \
    --epochs 5 \
    --batch-size 512
```

**效果：**
- 数据加载时间：10-20秒
- 快速验证GPU是否工作
- 5分钟内看到结果

### 方案3：监控数据加载进度

训练脚本会输出数据加载进度：

```
使用缓存数据加载 3043 只股票...
  K线缓存: data/parquet
  特征缓存: data/features

[100/3043] 已加载 98 只 (缓存命中: 95, 未命中: 3)
[200/3043] 已加载 196 只 (缓存命中: 190, 未命中: 6)
[300/3043] 已加载 294 只 (缓存命中: 285, 未命中: 9)
...
[3000/3043] 已加载 2850 只 (缓存命中: 2800, 未命中: 50)

数据加载完成:  ← 这之后GPU才开始工作
  成功: 2850 只
  失败: 193 只
```

**耐心等待这个阶段完成！**

---

## 🔍 如何确认GPU开始工作？

### 第1步：观察训练输出

数据加载完成后，会看到：

```
创建数据集...
✓ 训练集: 1,234,567 样本
✓ 验证集: 264,836 样本
✓ 测试集: 264,836 样本

创建模型...
✓ 模型参数量: 2,345,678

开始训练...  ← GPU从这里开始工作
======================================================================

Epoch [1/100] - Train Loss: 0.234567, Val Loss: 0.345678, Time: 15.34s
```

### 第2步：监控GPU

在另一个终端运行：

```bash
watch -n 1 nvidia-smi
```

**数据加载阶段（GPU空闲）：**
```
| GPU  Name                 | GPU-Util  | Memory-Usage |
|   0  NVIDIA A10           |     0%    |    3MB / 22GB |  ← GPU空闲
```

**训练阶段（GPU工作）：**
```
| GPU  Name                 | GPU-Util  | Memory-Usage |
|   0  NVIDIA A10           |    98%    |  18GB / 22GB |  ← GPU工作
```

---

## 🚀 推荐操作流程

### 第1步：快速测试（10秒数据加载）

```bash
python scripts/train_universal_model.py \
    --device cuda \
    --amp \
    --limit 100 \
    --epochs 5 \
    --batch-size 512 \
    --num-workers 2
```

**预期输出：**
```
使用缓存数据加载 100 只股票...
[100/100] 已加载 98 只 (缓存命中: 95, 未命中: 3)

数据加载完成:
  成功: 98 只
  失败: 2 只
  训练样本: 45,678

创建数据集...
✓ 训练集: 45,678 样本

创建模型...
✓ 模型参数量: 2,345,678

开始训练...
  混合精度: 启用
  DataLoader workers: 2
  Pin memory: True

Epoch [1/5] - Train Loss: 0.234567, Val Loss: 0.345678, Time: 12.34s
                                                                ↑
                                                        GPU开始工作了！
```

### 第2步：监控GPU（另一个终端）

```bash
watch -n 1 nvidia-smi
```

**应该看到GPU利用率从0%跳到90-100%**

### 第3步：正式训练

确认GPU工作后，使用完整配置：

```bash
python scripts/train_universal_model.py \
    --model-type transformer \
    --epochs 100 \
    --batch-size 1024 \
    --hidden-size 256 \
    --device cuda \
    --amp \
    --num-workers 4 \
    --pin-memory \
    --limit 1000
```

---

## 📊 时间线预估

### 使用1000只股票

```
00:00 - 开始运行
00:00 - 数据加载开始（内存占用上升）
00:02 - [500/1000] 已加载 490 只
00:04 - [1000/1000] 已加载 950 只
00:04 - 数据加载完成
00:04 - 创建数据集
00:05 - 创建模型
00:05 - 开始训练（GPU开始工作）  ← GPU从这里开始
00:05 - Epoch [1/100] - Time: 15s
00:06 - Epoch [2/100] - Time: 15s
...
01:30 - 训练完成
```

### 使用3000只股票

```
00:00 - 开始运行
00:00 - 数据加载开始（内存占用上升）
00:03 - [1000/3000] 已加载 950 只
00:06 - [2000/3000] 已加载 1900 只
00:09 - [3000/3000] 已加载 2850 只
00:10 - 数据加载完成
00:10 - 创建数据集
00:11 - 创建模型
00:11 - 开始训练（GPU开始工作）  ← GPU从这里开始
00:11 - Epoch [1/100] - Time: 25s
00:12 - Epoch [2/100] - Time: 25s
...
02:00 - 训练完成
```

---

## 💡 关键要点

### 1. 耐心等待数据加载

**数据加载是CPU密集型任务，GPU在这个阶段不工作是正常的！**

- 100只股票：10-20秒
- 500只股票：1-2分钟
- 1000只股票：2-4分钟
- 3000只股票：6-12分钟

### 2. 观察输出日志

看到这些输出说明GPU即将开始工作：

```
数据加载完成:  ← 数据加载结束
  成功: 2850 只

创建数据集...  ← 准备训练数据
✓ 训练集: 1,234,567 样本

创建模型...  ← 创建神经网络
✓ 模型参数量: 2,345,678

开始训练...  ← GPU从这里开始工作！
```

### 3. 使用限制股票数量

**推荐配置：**
```bash
--limit 1000  # 数据加载只需2-4分钟
```

### 4. 监控GPU

```bash
# 在另一个终端持续监控
watch -n 1 nvidia-smi
```

---

## 🔧 诊断命令

### 检查当前状态

```bash
# 检查是否有训练进程
ps aux | grep train_universal_model

# 检查GPU使用
nvidia-smi

# 检查内存使用
free -h
```

### 如果等待时间过长

**超过10分钟还在数据加载：**

1. **Ctrl+C 中断**
2. **使用更少的股票：**
   ```bash
   python scripts/train_universal_model.py \
       --device cuda \
       --amp \
       --limit 500
   ```

---

## ✨ 总结

### 问题根源

**GPU没有被使用是因为还在数据加载阶段！**

数据加载是CPU任务，GPU要等数据加载完成后才开始工作。

### 解决方案

1. ✅ **耐心等待** - 数据加载需要2-12分钟
2. ✅ **限制股票数量** - `--limit 1000` 加快数据加载
3. ✅ **先小规模测试** - `--limit 100` 快速验证
4. ✅ **监控进度** - 观察输出日志和GPU使用

### 推荐命令

```bash
# 快速测试（10秒数据加载）
python scripts/train_universal_model.py \
    --device cuda \
    --amp \
    --limit 100 \
    --epochs 5

# 正式训练（2-4分钟数据加载）
python scripts/train_universal_model.py \
    --model-type transformer \
    --epochs 100 \
    --batch-size 1024 \
    --hidden-size 256 \
    --device cuda \
    --amp \
    --num-workers 4 \
    --pin-memory \
    --limit 1000
```

**耐心等待数据加载完成，GPU很快就会开始工作！** 🚀
