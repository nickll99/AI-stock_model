# GPUè®­ç»ƒåŠ é€ŸæŒ‡å—

## ğŸš€ é—®é¢˜å·²è§£å†³ï¼

**è®­ç»ƒè„šæœ¬ç°åœ¨æ”¯æŒå¤šç§åŠ é€ŸæŠ€æœ¯ï¼Œå¯ä»¥å……åˆ†åˆ©ç”¨GPUæ˜¾å­˜å’Œç®—åŠ›ï¼**

---

## âš¡ åŠ é€ŸæŠ€æœ¯

### 1. æ··åˆç²¾åº¦è®­ç»ƒï¼ˆAMPï¼‰

**æœ€é‡è¦çš„åŠ é€ŸæŠ€æœ¯ï¼** ä½¿ç”¨FP16ä»£æ›¿FP32ï¼Œé€Ÿåº¦æå‡2-3å€ï¼Œæ˜¾å­˜å ç”¨å‡åŠã€‚

```bash
# å¯ç”¨æ··åˆç²¾åº¦è®­ç»ƒ
python scripts/train_universal_model.py --amp --device cuda
```

**æ•ˆæœï¼š**
- é€Ÿåº¦æå‡ï¼š2-3å€
- æ˜¾å­˜å ç”¨ï¼šå‡å°‘50%
- ç²¾åº¦æŸå¤±ï¼šå‡ ä¹æ— å½±å“

### 2. å¢å¤§Batch Size

æ˜¾å­˜æ²¡å æ»¡æ—¶ï¼Œå¢å¤§batch sizeå¯ä»¥æå‡è®­ç»ƒé€Ÿåº¦ã€‚

```bash
# å¢å¤§batch sizeåˆ°512æˆ–æ›´å¤§
python scripts/train_universal_model.py \
    --batch-size 512 \
    --amp \
    --device cuda
```

**æ¨èé…ç½®ï¼š**
| æ˜¾å­˜å¤§å° | æ¨èBatch Size | è¯´æ˜ |
|---------|---------------|------|
| 8GB | 256-512 | æ ‡å‡†é…ç½® |
| 12GB | 512-1024 | é«˜æ€§èƒ½ |
| 16GB+ | 1024-2048 | æè‡´æ€§èƒ½ |

### 3. DataLoaderä¼˜åŒ–

ä½¿ç”¨å¤šè¿›ç¨‹åŠ è½½æ•°æ®ï¼Œé¿å…GPUç­‰å¾…æ•°æ®ã€‚

```bash
# ä½¿ç”¨4ä¸ªworkerè¿›ç¨‹
python scripts/train_universal_model.py \
    --num-workers 4 \
    --pin-memory \
    --amp \
    --device cuda
```

**æ¨èé…ç½®ï¼š**
- CPUæ ¸å¿ƒæ•° >= 8: `--num-workers 4`
- CPUæ ¸å¿ƒæ•° >= 16: `--num-workers 8`

### 4. æ¢¯åº¦ç´¯ç§¯

æ˜¾å­˜ä¸è¶³æ—¶ï¼Œé€šè¿‡æ¢¯åº¦ç´¯ç§¯æ¨¡æ‹Ÿæ›´å¤§çš„batch sizeã€‚

```bash
# æ¢¯åº¦ç´¯ç§¯4æ­¥ï¼Œç›¸å½“äºbatch_size * 4
python scripts/train_universal_model.py \
    --batch-size 256 \
    --gradient-accumulation-steps 4 \
    --amp \
    --device cuda
```

**æ•ˆæœï¼š** ç›¸å½“äºbatch size = 256 * 4 = 1024

---

## ğŸ¯ æ¨èé…ç½®

### é…ç½®1ï¼šæè‡´æ€§èƒ½ï¼ˆæ¨èï¼‰

```bash
python scripts/train_universal_model.py \
    --model-type transformer \
    --epochs 100 \
    --batch-size 512 \
    --hidden-size 256 \
    --device cuda \
    --amp \
    --num-workers 4 \
    --pin-memory
```

**é€‚ç”¨åœºæ™¯ï¼š**
- GPUæ˜¾å­˜ >= 12GB
- è¿½æ±‚æœ€å¿«è®­ç»ƒé€Ÿåº¦
- æ•°æ®å·²é¢„çƒ­åˆ°ç¼“å­˜

**é¢„æœŸæ€§èƒ½ï¼š**
- è®­ç»ƒé€Ÿåº¦ï¼š2-3å€æå‡
- æ˜¾å­˜å ç”¨ï¼š6-8GB
- å®Œæ•´è®­ç»ƒæ—¶é—´ï¼š1-1.5å°æ—¶

### é…ç½®2ï¼šå¹³è¡¡æ€§èƒ½

```bash
python scripts/train_universal_model.py \
    --model-type lstm \
    --epochs 50 \
    --batch-size 256 \
    --hidden-size 128 \
    --device cuda \
    --amp \
    --num-workers 2
```

**é€‚ç”¨åœºæ™¯ï¼š**
- GPUæ˜¾å­˜ 8-12GB
- å¹³è¡¡é€Ÿåº¦å’Œèµ„æº
- æ ‡å‡†è®­ç»ƒéœ€æ±‚

**é¢„æœŸæ€§èƒ½ï¼š**
- è®­ç»ƒé€Ÿåº¦ï¼š1.5-2å€æå‡
- æ˜¾å­˜å ç”¨ï¼š4-6GB
- å®Œæ•´è®­ç»ƒæ—¶é—´ï¼š1.5-2å°æ—¶

### é…ç½®3ï¼šæ˜¾å­˜å—é™

```bash
python scripts/train_universal_model.py \
    --model-type lstm \
    --epochs 50 \
    --batch-size 128 \
    --hidden-size 64 \
    --device cuda \
    --amp \
    --gradient-accumulation-steps 2
```

**é€‚ç”¨åœºæ™¯ï¼š**
- GPUæ˜¾å­˜ <= 8GB
- æ˜¾å­˜ä¸è¶³ä½†æƒ³ç”¨GPU
- å°æ¨¡å‹è®­ç»ƒ

**é¢„æœŸæ€§èƒ½ï¼š**
- è®­ç»ƒé€Ÿåº¦ï¼š1.5å€æå‡
- æ˜¾å­˜å ç”¨ï¼š2-4GB
- å®Œæ•´è®­ç»ƒæ—¶é—´ï¼š2-3å°æ—¶

---

## ğŸ“Š æ€§èƒ½å¯¹æ¯”

### ä¸åŒé…ç½®çš„æ€§èƒ½å¯¹æ¯”

| é…ç½® | Batch Size | AMP | Workers | è®­ç»ƒæ—¶é—´ | æ˜¾å­˜å ç”¨ | æå‡ |
|------|-----------|-----|---------|---------|---------|------|
| åŸºç¡€ | 128 | âŒ | 0 | 4å°æ—¶ | 8GB | 1x |
| +AMP | 128 | âœ… | 0 | 2å°æ—¶ | 4GB | 2x |
| +Batch | 512 | âœ… | 0 | 1.5å°æ—¶ | 6GB | 2.7x |
| +Workers | 512 | âœ… | 4 | 1.2å°æ—¶ | 6GB | 3.3x |
| æè‡´ | 1024 | âœ… | 8 | 1å°æ—¶ | 8GB | 4x |

### æ··åˆç²¾åº¦è®­ç»ƒæ•ˆæœ

| æŒ‡æ ‡ | FP32 | FP16 (AMP) | æå‡ |
|------|------|-----------|------|
| è®­ç»ƒé€Ÿåº¦ | 100% | 200-300% | 2-3x |
| æ˜¾å­˜å ç”¨ | 100% | 50% | 2x |
| æ¨¡å‹ç²¾åº¦ | åŸºå‡† | -0.1% | å‡ ä¹æ— æŸ |

---

## ğŸ” ç›‘æ§GPUä½¿ç”¨

### å®æ—¶ç›‘æ§

```bash
# åœ¨å¦ä¸€ä¸ªç»ˆç«¯è¿è¡Œ
watch -n 1 nvidia-smi
```

**å…³é”®æŒ‡æ ‡ï¼š**
- GPUåˆ©ç”¨ç‡ï¼šåº”è¯¥æ¥è¿‘100%
- æ˜¾å­˜ä½¿ç”¨ï¼šåº”è¯¥å ç”¨70-90%
- æ¸©åº¦ï¼šåº”è¯¥åœ¨70-85Â°C

### æ£€æŸ¥æ˜¯å¦å……åˆ†åˆ©ç”¨GPU

**âœ… è‰¯å¥½çŠ¶æ€ï¼š**
```
+-----------------------------------------------------------------------------+
| GPU  Name            | GPU-Util  | Memory-Usage |
|=============================================================================|
|   0  RTX 4090        |    98%    |  18GB / 24GB |  â† GPUåˆ©ç”¨ç‡é«˜
+-----------------------------------------------------------------------------+
```

**âŒ æœªå……åˆ†åˆ©ç”¨ï¼š**
```
+-----------------------------------------------------------------------------+
| GPU  Name            | GPU-Util  | Memory-Usage |
|=============================================================================|
|   0  RTX 4090        |    45%    |   6GB / 24GB |  â† GPUåˆ©ç”¨ç‡ä½ï¼Œæ˜¾å­˜æœªå æ»¡
+-----------------------------------------------------------------------------+
```

**è§£å†³æ–¹æ¡ˆï¼š**
1. å¢å¤§batch size
2. å¯ç”¨æ··åˆç²¾åº¦è®­ç»ƒ
3. å¢åŠ DataLoader workers

---

## ğŸ“ æœ€ä½³å®è·µ

### 1. é€æ­¥ä¼˜åŒ–

```bash
# ç¬¬1æ­¥ï¼šåŸºç¡€é…ç½®
python scripts/train_universal_model.py --device cuda

# ç¬¬2æ­¥ï¼šå¯ç”¨AMP
python scripts/train_universal_model.py --device cuda --amp

# ç¬¬3æ­¥ï¼šå¢å¤§batch size
python scripts/train_universal_model.py --device cuda --amp --batch-size 512

# ç¬¬4æ­¥ï¼šä¼˜åŒ–DataLoader
python scripts/train_universal_model.py \
    --device cuda \
    --amp \
    --batch-size 512 \
    --num-workers 4 \
    --pin-memory
```

### 2. æ‰¾åˆ°æœ€ä½³Batch Size

```bash
# æµ‹è¯•è„šæœ¬
for bs in 128 256 512 1024; do
    echo "Testing batch size: $bs"
    python scripts/train_universal_model.py \
        --device cuda \
        --amp \
        --batch-size $bs \
        --epochs 5 \
        --limit 100
done
```

### 3. ç›‘æ§è®­ç»ƒé€Ÿåº¦

```python
# åœ¨è®­ç»ƒè¾“å‡ºä¸­æŸ¥çœ‹æ¯ä¸ªepochçš„æ—¶é—´
Epoch [1/100] - Train Loss: 0.234567, Val Loss: 0.345678, Time: 45.23s
                                                                  â†‘
                                                            å…³æ³¨è¿™ä¸ªæ—¶é—´
```

**ç›®æ ‡ï¼š**
- åŸºç¡€é…ç½®ï¼š60-90ç§’/epoch
- ä¼˜åŒ–åï¼š20-30ç§’/epoch
- æè‡´ä¼˜åŒ–ï¼š10-15ç§’/epoch

---

## ğŸ”§ æ•…éšœæ’é™¤

### é—®é¢˜1ï¼šæ˜¾å­˜ä¸è¶³ï¼ˆOOMï¼‰

**ç—‡çŠ¶ï¼š**
```
RuntimeError: CUDA out of memory
```

**è§£å†³æ–¹æ¡ˆï¼š**
```bash
# æ–¹æ¡ˆ1ï¼šå‡å°batch size
python scripts/train_universal_model.py --batch-size 64 --amp --device cuda

# æ–¹æ¡ˆ2ï¼šä½¿ç”¨æ¢¯åº¦ç´¯ç§¯
python scripts/train_universal_model.py \
    --batch-size 128 \
    --gradient-accumulation-steps 4 \
    --amp \
    --device cuda

# æ–¹æ¡ˆ3ï¼šå‡å°æ¨¡å‹å¤§å°
python scripts/train_universal_model.py \
    --hidden-size 64 \
    --batch-size 256 \
    --amp \
    --device cuda
```

### é—®é¢˜2ï¼šGPUåˆ©ç”¨ç‡ä½

**ç—‡çŠ¶ï¼š** nvidia-smiæ˜¾ç¤ºGPUåˆ©ç”¨ç‡ < 50%

**åŸå› ï¼š**
1. Batch sizeå¤ªå°
2. DataLoaderå¤ªæ…¢ï¼ˆCPUç“¶é¢ˆï¼‰
3. æ²¡æœ‰å¯ç”¨AMP

**è§£å†³æ–¹æ¡ˆï¼š**
```bash
# å¢å¤§batch size + å¯ç”¨AMP + å¤šworker
python scripts/train_universal_model.py \
    --batch-size 512 \
    --amp \
    --num-workers 4 \
    --device cuda
```

### é—®é¢˜3ï¼šè®­ç»ƒé€Ÿåº¦æ²¡æœ‰æå‡

**ç—‡çŠ¶ï¼š** å¯ç”¨AMPåé€Ÿåº¦æ²¡æœ‰æ˜æ˜¾æå‡

**åŸå› ï¼š**
1. æ¨¡å‹å¤ªå°ï¼ŒAMPä¼˜åŠ¿ä¸æ˜æ˜¾
2. DataLoaderæ˜¯ç“¶é¢ˆ
3. æ•°æ®ä»æ•°æ®åº“åŠ è½½ï¼ˆæœªä½¿ç”¨ç¼“å­˜ï¼‰

**è§£å†³æ–¹æ¡ˆï¼š**
```bash
# 1. ç¡®ä¿ä½¿ç”¨ç¼“å­˜æ•°æ®
python scripts/prepare_training_data.py --symbols all --workers 8 --resume

# 2. ä½¿ç”¨æ›´å¤§çš„æ¨¡å‹å’Œbatch size
python scripts/train_universal_model.py \
    --model-type transformer \
    --hidden-size 256 \
    --batch-size 512 \
    --amp \
    --num-workers 4 \
    --device cuda
```

### é—®é¢˜4ï¼šDataLoader workersæŠ¥é”™

**ç—‡çŠ¶ï¼š**
```
RuntimeError: DataLoader worker (pid XXXX) is killed by signal
```

**è§£å†³æ–¹æ¡ˆï¼š**
```bash
# å‡å°‘workeræ•°é‡
python scripts/train_universal_model.py \
    --num-workers 2 \
    --amp \
    --device cuda

# æˆ–è€…ç¦ç”¨workers
python scripts/train_universal_model.py \
    --num-workers 0 \
    --amp \
    --device cuda
```

---

## ğŸ“ å‚æ•°è¯´æ˜

### æ€§èƒ½ç›¸å…³å‚æ•°

| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ | æ¨èå€¼ |
|------|--------|------|--------|
| `--amp` | False | å¯ç”¨æ··åˆç²¾åº¦è®­ç»ƒ | å¯ç”¨ï¼ˆGPUï¼‰ |
| `--batch-size` | 128 | æ‰¹æ¬¡å¤§å° | 256-1024 |
| `--num-workers` | 4 | DataLoaderè¿›ç¨‹æ•° | 2-8 |
| `--pin-memory` | True | å›ºå®šå†…å­˜ | å¯ç”¨ï¼ˆGPUï¼‰ |
| `--gradient-accumulation-steps` | 1 | æ¢¯åº¦ç´¯ç§¯æ­¥æ•° | 1-4 |

### æ¨¡å‹ç›¸å…³å‚æ•°

| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ | æ¨èå€¼ |
|------|--------|------|--------|
| `--model-type` | lstm | æ¨¡å‹ç±»å‹ | transformer |
| `--hidden-size` | 128 | éšè—å±‚å¤§å° | 128-256 |
| `--num-layers` | 2 | å±‚æ•° | 2-4 |
| `--dropout` | 0.2 | Dropoutç‡ | 0.1-0.3 |

---

## âœ¨ æ€»ç»“

### æ ¸å¿ƒä¼˜åŒ–æŠ€æœ¯

1. âœ… **æ··åˆç²¾åº¦è®­ç»ƒï¼ˆAMPï¼‰** - é€Ÿåº¦æå‡2-3å€ï¼Œæ˜¾å­˜å‡åŠ
2. âœ… **å¢å¤§Batch Size** - å……åˆ†åˆ©ç”¨GPUç®—åŠ›
3. âœ… **DataLoaderä¼˜åŒ–** - é¿å…GPUç­‰å¾…æ•°æ®
4. âœ… **æ¢¯åº¦ç´¯ç§¯** - æ˜¾å­˜ä¸è¶³æ—¶çš„è§£å†³æ–¹æ¡ˆ

### æ¨èå‘½ä»¤

```bash
# æè‡´æ€§èƒ½é…ç½®
python scripts/train_universal_model.py \
    --model-type transformer \
    --epochs 100 \
    --batch-size 512 \
    --hidden-size 256 \
    --device cuda \
    --amp \
    --num-workers 4 \
    --pin-memory
```

### é¢„æœŸæ•ˆæœ

| æŒ‡æ ‡ | ä¼˜åŒ–å‰ | ä¼˜åŒ–å | æå‡ |
|------|--------|--------|------|
| è®­ç»ƒæ—¶é—´ | 4å°æ—¶ | 1-1.5å°æ—¶ | 3-4x |
| GPUåˆ©ç”¨ç‡ | 40-50% | 90-100% | 2x |
| æ˜¾å­˜å ç”¨ | 8GB | 6-8GB | æ›´é«˜æ•ˆ |

ç°åœ¨ä½ å¯ä»¥å……åˆ†åˆ©ç”¨GPUè¿›è¡Œé«˜é€Ÿè®­ç»ƒäº†ï¼ğŸš€
